#include <tracker_movement/Viewer.h>

Viewer::Viewer(){
    this->points = false;
    this->tracker=new Tracker();
}

Viewer::~Viewer(){
    openni::OpenNI::shutdown();

}


openni::Status Viewer::Init(int argc, char **argv){
	statusOpenni = openni::OpenNI::initialize();
    if (statusOpenni != openni::STATUS_OK)
    {
        ROS_ERROR("Failed to initialize OpenNI\n%s\n", openni::OpenNI::getExtendedError());
        exit(3);
    }

    statusOpenni = openDevice(argc, argv);
    tracker = new Tracker(points);
    niteStatus = tracker->initialize(&kinect);

    if (niteStatus != nite::STATUS_OK)
    {
        cerr << "Couldn't create user tracker" << endl ;
        exit(3); //TODO cambiar por salida de errores
    }

    depth.create(kinect, openni::SENSOR_DEPTH);
    depth.start();

    ROS_INFO_STREAM("Start moving around to get detected... (PSI pose may be required for skeleton calibration, depending on the configuration)" );
    return statusOpenni;
}

openni::Status Viewer::openDevice(int argc, char** argv){
    const char* deviceUri = openni::ANY_DEVICE;

    for (int i = 1; i < argc; ++i)
    {
        if (strcmp(argv[i], "-device") == 0)
        {
            deviceUri = argv[i+1];
            ROS_INFO("Using a oni file: %s", deviceUri);
        }
        else{
            if(strcmp(argv[i], "-points" ) == 0){
                this->points = true;
                ROS_INFO_STREAM("Showing skeleton's joints");
            }
        }
    }
    statusOpenni = kinect.open(deviceUri);

    if (statusOpenni != openni::STATUS_OK)
    {

        ROS_ERROR("Failed to open device\n%s\n", openni::OpenNI::getExtendedError());
        return statusOpenni;
    }

}

void Viewer::drawLimb(cv::Mat& image, const nite::SkeletonJoint& joint1, const nite::SkeletonJoint& joint2)
{

    nite::UserTracker* userTracker = tracker->getUserTracker();

    float coordinates[6] = {0};


	userTracker->convertJointCoordinatesToDepth(joint1.getPosition().x, joint1.getPosition().y, joint1.getPosition().z, &coordinates[0], &coordinates[1]);


	userTracker->convertJointCoordinatesToDepth(joint2.getPosition().x, joint2.getPosition().y, joint2.getPosition().z, &coordinates[3], &coordinates[4]);




	coordinates[0] *= image.cols/(float)depthFrame.getVideoMode().getResolutionX();
	coordinates[1] *= image.rows/(float)depthFrame.getVideoMode().getResolutionY();
	coordinates[3] *= image.cols/(float)depthFrame.getVideoMode().getResolutionX();
	coordinates[4] *= image.rows/(float)depthFrame.getVideoMode().getResolutionY();


    cv::Point2f point1(coordinates[0],coordinates[1]);
    cv::Point2f point2(coordinates[3],coordinates[4]);


    cv::Scalar color;

    if (joint1.getPositionConfidence() == 1 && joint2.getPositionConfidence() == 1)
    {
        color = static_cast<cv::Scalar>(cv::Vec3b(0, 255, 255));
    }
    else if (joint1.getPositionConfidence() < 0.5f || joint2.getPositionConfidence() < 0.5f)
    {
    	return;
    }
    else
    {
    	color = static_cast<cv::Scalar>(cv::Vec3b(127, 127, 127));
    }


    cv::line( image, point1, point2, color ,2,CV_AA);


	if (joint1.getPositionConfidence() == 1)
	{
        color = static_cast<cv::Scalar>(cv::Vec3b(0, 255, 255));
    }
	else
	{
		color = static_cast<cv::Scalar>(cv::Vec3b(127, 127, 127));
	}

    cv::circle( image, point1, 5, color, -1, CV_AA );


	if (joint2.getPositionConfidence() == 1)
	{
        color = static_cast<cv::Scalar>(cv::Vec3b(0, 255, 255));
	}
	else
	{
        color = static_cast<cv::Scalar>(cv::Vec3b(127, 127, 127));
	}


    cv::circle( image, point2, 5, color, -1, CV_AA );

}


void Viewer::drawSkeleton(cv::Mat& image, const nite::UserData& user){

    nite::UserTracker* userTracker = tracker->getUserTracker();

    drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_HEAD), user.getSkeleton().getJoint(nite::JOINT_NECK));
    drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_NECK), user.getSkeleton().getJoint(nite::JOINT_LEFT_SHOULDER));

    drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_SHOULDER), user.getSkeleton().getJoint(nite::JOINT_LEFT_ELBOW));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_ELBOW), user.getSkeleton().getJoint(nite::JOINT_LEFT_HAND));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_RIGHT_SHOULDER), user.getSkeleton().getJoint(nite::JOINT_RIGHT_ELBOW));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_RIGHT_ELBOW), user.getSkeleton().getJoint(nite::JOINT_RIGHT_HAND));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_SHOULDER), user.getSkeleton().getJoint(nite::JOINT_RIGHT_SHOULDER));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_SHOULDER), user.getSkeleton().getJoint(nite::JOINT_TORSO));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_RIGHT_SHOULDER), user.getSkeleton().getJoint(nite::JOINT_TORSO));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_TORSO), user.getSkeleton().getJoint(nite::JOINT_LEFT_HIP));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_TORSO), user.getSkeleton().getJoint(nite::JOINT_RIGHT_HIP));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_HIP), user.getSkeleton().getJoint(nite::JOINT_RIGHT_HIP));


	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_HIP), user.getSkeleton().getJoint(nite::JOINT_LEFT_KNEE));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_LEFT_KNEE), user.getSkeleton().getJoint(nite::JOINT_LEFT_FOOT));

	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_RIGHT_HIP), user.getSkeleton().getJoint(nite::JOINT_RIGHT_KNEE));
	drawLimb(image, user.getSkeleton().getJoint(nite::JOINT_RIGHT_KNEE), user.getSkeleton().getJoint(nite::JOINT_RIGHT_FOOT));

    //Dibujar lineas y mÃ¡ximo

}

nite::Status Viewer::run(std_msgs::String& cmdGripper){
    nite::UserData user;

    niteStatus = tracker->run(cmdGripper, user);

    depthFrame = tracker->getUserTrackerFrame().getDepthFrame();


    depthImageBuffer = (openni::DepthPixel*)depthFrame.getData();

    cvDepthFrame.create(depthFrame.getHeight(), depthFrame.getWidth(), CV_16UC1);

    memcpy( cvDepthFrame.data, depthImageBuffer, depthFrame.getHeight()*depthFrame.getWidth()*sizeof(uint16_t) );



    cv::Mat cvNormalDepthFrame; // destination image for visualization

    cv::normalize(cvDepthFrame, cvNormalDepthFrame, 0, 255, CV_MINMAX);
    cvNormalDepthFrame.convertTo(cvNormalDepthFrame, CV_8UC3);

    if (user.getSkeleton().getState() == nite::SKELETON_TRACKED)
    {
        drawSkeleton(cvNormalDepthFrame, user);

    }
    //MOSTRAR
    cv::namedWindow("Depth", cv::WINDOW_AUTOSIZE);
    //cv::namedWindow("Input3", cv::WINDOW_AUTOSIZE);
    cv::imshow("Depth", cvNormalDepthFrame);

    cv::waitKey(30);

    return niteStatus;
}
